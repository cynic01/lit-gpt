{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative examples for each metric\n",
    "pkl -> UniEval coherence\n",
    "\n",
    "csv -> bartscore\n",
    "\n",
    "json -> GPT4 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UniEval coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/workspaces/lit-gpt/out/inference/pythia-160m-deduped-oasst1-base-eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>label</th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>engagingness</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am making mayonnaise, it was starting to thi...</td>\n",
       "      <td>Nothing, hasnothing, isnothing, isnothing, doe...</td>\n",
       "      <td>Yes, it's possible to fix runny mayonnaise! Th...</td>\n",
       "      <td>0.068879</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.366695</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.109115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is optimal Mayonnaise thickness?</td>\n",
       "      <td>].\n",
       "\n",
       "## From the Online Instructional Video\n",
       "\n",
       "Wh...</td>\n",
       "      <td>The optimal mayonnaise thickness will depend o...</td>\n",
       "      <td>0.111042</td>\n",
       "      <td>0.211688</td>\n",
       "      <td>2.023898</td>\n",
       "      <td>0.854118</td>\n",
       "      <td>0.111710</td>\n",
       "      <td>0.662491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am making mayonnaise, it was starting to thi...</td>\n",
       "      <td>ziemzaza\n",
       "zaunikasannia se zabauza obytojni,\n",
       "zn...</td>\n",
       "      <td>Yes, it's possible to fix runny mayonnaise! Th...</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>0.768196</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>0.180617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is optimal Mayonnaise thickness?</td>\n",
       "      <td>)?\n",
       "\n",
       "Chop-up-the-chop, the new or the old.\n",
       "\n",
       "Hav...</td>\n",
       "      <td>The optimal thickness of mayonnaise can vary d...</td>\n",
       "      <td>0.154121</td>\n",
       "      <td>0.608273</td>\n",
       "      <td>1.015807</td>\n",
       "      <td>0.983253</td>\n",
       "      <td>0.117305</td>\n",
       "      <td>0.575752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am making mayonnaise, it was starting to thi...</td>\n",
       "      <td>, may be,\n",
       "\n",
       "Teddy\n",
       "\n",
       "I am a student at Berkeley C...</td>\n",
       "      <td>Yes, it is possible to salvage your mayonnaise...</td>\n",
       "      <td>0.129091</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.586473</td>\n",
       "      <td>0.955527</td>\n",
       "      <td>0.123747</td>\n",
       "      <td>0.445577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Does this mean that Into the Breach is a game ...</td>\n",
       "      <td>?Or?And?In a game with a better better story?A...</td>\n",
       "      <td>A game is broadly considered to be perfect inf...</td>\n",
       "      <td>0.471146</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>50.285279</td>\n",
       "      <td>0.770567</td>\n",
       "      <td>0.506659</td>\n",
       "      <td>10.422231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>I've recently started playing the turn-based s...</td>\n",
       "      <td>它\n",
       "\n",
       "[2] When you reach the point of your first ...</td>\n",
       "      <td>In the context of Into the Breach, \"perfect in...</td>\n",
       "      <td>0.762709</td>\n",
       "      <td>0.993709</td>\n",
       "      <td>11.326418</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>2.988643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Does this mean that Into the Breach is a game ...</td>\n",
       "      <td>?Or is it just a game of perfect information?T...</td>\n",
       "      <td>Yes, even though there is a lot of strategy in...</td>\n",
       "      <td>0.068524</td>\n",
       "      <td>0.625953</td>\n",
       "      <td>13.947606</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>3.115427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>I've recently started playing the turn-based s...</td>\n",
       "      <td>名称](http://en.wikipedia.org/wiki/File:File:Fil...</td>\n",
       "      <td>In the context of Into the Breach, \"perfect in...</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.029742</td>\n",
       "      <td>0.222352</td>\n",
       "      <td>0.423337</td>\n",
       "      <td>0.225476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>Does this mean that Into the Breach is a game ...</td>\n",
       "      <td>: has: is: is: is: is: is: is: is: is: is: is:...</td>\n",
       "      <td>Depends.\n",
       "\n",
       "Does the game feature a line of sigh...</td>\n",
       "      <td>0.052499</td>\n",
       "      <td>0.081561</td>\n",
       "      <td>0.602606</td>\n",
       "      <td>0.633863</td>\n",
       "      <td>0.045847</td>\n",
       "      <td>0.283275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1685 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     I am making mayonnaise, it was starting to thi...   \n",
       "1                 What is optimal Mayonnaise thickness?   \n",
       "2     I am making mayonnaise, it was starting to thi...   \n",
       "3                 What is optimal Mayonnaise thickness?   \n",
       "4     I am making mayonnaise, it was starting to thi...   \n",
       "...                                                 ...   \n",
       "1680  Does this mean that Into the Breach is a game ...   \n",
       "1681  I've recently started playing the turn-based s...   \n",
       "1682  Does this mean that Into the Breach is a game ...   \n",
       "1683  I've recently started playing the turn-based s...   \n",
       "1684  Does this mean that Into the Breach is a game ...   \n",
       "\n",
       "                                                 output  \\\n",
       "0     Nothing, hasnothing, isnothing, isnothing, doe...   \n",
       "1     ].\n",
       "\n",
       "## From the Online Instructional Video\n",
       "\n",
       "Wh...   \n",
       "2     ziemzaza\n",
       "zaunikasannia se zabauza obytojni,\n",
       "zn...   \n",
       "3     )?\n",
       "\n",
       "Chop-up-the-chop, the new or the old.\n",
       "\n",
       "Hav...   \n",
       "4     , may be,\n",
       "\n",
       "Teddy\n",
       "\n",
       "I am a student at Berkeley C...   \n",
       "...                                                 ...   \n",
       "1680  ?Or?And?In a game with a better better story?A...   \n",
       "1681  它\n",
       "\n",
       "[2] When you reach the point of your first ...   \n",
       "1682  ?Or is it just a game of perfect information?T...   \n",
       "1683  名称](http://en.wikipedia.org/wiki/File:File:Fil...   \n",
       "1684  : has: is: is: is: is: is: is: is: is: is: is:...   \n",
       "\n",
       "                                                  label  naturalness  \\\n",
       "0     Yes, it's possible to fix runny mayonnaise! Th...     0.068879   \n",
       "1     The optimal mayonnaise thickness will depend o...     0.111042   \n",
       "2     Yes, it's possible to fix runny mayonnaise! Th...     0.036620   \n",
       "3     The optimal thickness of mayonnaise can vary d...     0.154121   \n",
       "4     Yes, it is possible to salvage your mayonnaise...     0.129091   \n",
       "...                                                 ...          ...   \n",
       "1680  A game is broadly considered to be perfect inf...     0.471146   \n",
       "1681  In the context of Into the Breach, \"perfect in...     0.762709   \n",
       "1682  Yes, even though there is a lot of strategy in...     0.068524   \n",
       "1683  In the context of Into the Breach, \"perfect in...     0.439139   \n",
       "1684  Depends.\n",
       "\n",
       "Does the game feature a line of sigh...     0.052499   \n",
       "\n",
       "      coherence  engagingness  groundedness  understandability    overall  \n",
       "0      0.005465      0.036438      0.366695           0.068096   0.109115  \n",
       "1      0.211688      2.023898      0.854118           0.111710   0.662491  \n",
       "2      0.049723      0.012429      0.768196           0.036118   0.180617  \n",
       "3      0.608273      1.015807      0.983253           0.117305   0.575752  \n",
       "4      0.433045      0.586473      0.955527           0.123747   0.445577  \n",
       "...         ...           ...           ...                ...        ...  \n",
       "1680   0.077505     50.285279      0.770567           0.506659  10.422231  \n",
       "1681   0.993709     11.326418      0.999303           0.861076   2.988643  \n",
       "1682   0.625953     13.947606      0.869565           0.065486   3.115427  \n",
       "1683   0.012811      0.029742      0.222352           0.423337   0.225476  \n",
       "1684   0.081561      0.602606      0.633863           0.045847   0.283275  \n",
       "\n",
       "[1685 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014245388724036"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.coherence.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Why don't people like the many-worlds interpretation of quantum mechanics?\",\n",
       "        'Yes, the many-worlds interpretation of quantum mechanics is a complex and multifaceted field. It is often used to explain the laws of physics, which allow for the existence of quantum systems in a way that would be impossible without the existence of the large scale objects. However, quantum mechanics is not meant to be taken literally. It is a philosophical and practical approach that aims to explain and interpret quantum systems.\\n\\nThe multiple-worlds interpretation of quantum mechanics is a complex and multifaceted approach that seeks to understand the laws of physics and the behavior of quantum systems. It is a departure from the more idealistic interpretations of quantum mechanics that were used by philosophers such as Bertrand Russell and Thomas W. Thorne.',\n",
       "        0.999531],\n",
       "       ['Can you list the issues with using a symmetric probability distribution when modelling problems?',\n",
       "        'The reason is that while symmetric probability distributions can be useful for some problems, they can fail to capture all the possible events of interest. In particular, symmetric probabilities can lead to inconsistent or incorrect results. For example, if you have a set of events that could lead to the same outcome, then you could be unable to capture the events that lead to the opposite outcome, even if they are not known beforehand.\\n\\nIn general, the answer to this question depends on the specific problem you have in mind. As an example, consider a system where you have a set of events, each occurring in a sequence of events, and consider a transition between these events. For example, you could have a system where you want to find the probability of transitioning between events, and then look at the transition probabilities of each event.\\n\\nThe choice of solution depends on the specific problem you have in mind. For example, you could look at the probability distributions of the probabilities of transitioning between events and then look at the transition probabilities of each event. In this case, the probabilities of transitioning between events and then evaluating the probability of transitioning between events are not known beforehand.\\n\\nIt is important to note that if you are trying to model problems that are not known beforehand, you may not be able to capture all possible events. For example, if you have a system where you have a set of events, and you want to make decisions about the outcomes of the events, then you could model problems that are outside of your control.',\n",
       "        0.999569],\n",
       "       ['Can you give me a summary of all the important historical events that took place on that date?',\n",
       "        \"The Roman and Byzantine emperors of Constantinople (381-270 BC) had a complex relationship with each other, as well as with their respective emperors and their respective cultural backgrounds. However, the most significant historical events that took place on that date were the Battle of Agathoc too soon after the fall of Constantinople.\\n\\nWhile the Roman Empire saw significant military victories and invasions, it also faced a number of challenges, including the loss of key cities, the decline of the Eastern Rift, the weakening of the Silk Road, and the collapse of the Iron Age.\\n\\nOverall, the Roman Empire faced a number of challenges, including the rise of the empire's economic power, the spread of empires, and the eventual collapse of the Eastern Rift. However, the most significant historical event that took place on that date was the Battle of Agathoc which was fought between the Byzantines and the Byzantines.\\n\\nDuring the Battle of Agathoc, the two armies met in a central square to form a potential future union. Aftermath:\\n\\n* Battle of Agathoc, a major battle involving the combined armies of the two cities, battles with the Byzantines, and the defeat of the latter two cities.\\n* Battle of Agathoc, a major battle involving the Byzantines and the Byzantian Empire.\\n* Battle of Agathoc, a major battle involving the Byzantines and the Romans.\\n* Battle of Agathoc, a major battle involving the Byzantines and the Romans.\\n\\nOverall, the Roman and Byzantine emperors faced a number of challenges, including the rise of the Eastern Rift, the fall of the Iron Age, and the weakening of the Western Roman Empire.\",\n",
       "        0.99959],\n",
       "       ['ok, perfect. what tools can we use for enhancing the managerial performance? give me some tools for each point you provided. for example I know that I can use Microsoft Project for project managing.',\n",
       "        'The following are some suggestions for enhancing the managerial performance:\\n\\n1. Use the \"check\" feature, which allows you to keep track of your progress throughout the day. You can use the \"check\" feature to check all your daily tasks and make sure you are doing the things that the manager should do to complete your tasks.\\n\\n2. Use the \"max\" feature, which allows you to limit your work to a certain number of tasks, causing the manager to stop and prioritize tasks that are most important to you. You can use the \"max\" feature to limit the number of tasks to a certain number, but keep the limit to a certain number.\\n\\n3. Use the \"work\" feature, which allows you to search for specific tasks that you need done and prioritize them based on your needs. For example, you can search for \"tasks to complete\" and \"tasks to complete\" by clicking on the \"tasks\" tab.\\n\\n4. Use the \"spam\" feature, which allows you to check your daily tasks and make them skip when they are not needed or when they are not needed. You can use the \"spam\" feature to check your weekly tasks and make sure you are not missing any important tasks.\\n\\nHere are some suggestions for enhancing the managerial performance:\\n\\n1. Keep in mind that there are many managerial processes and tasks that require more time, such as managing projects or prioritizing tasks. You can choose to prioritize tasks based on their importance, rather than the urgency of the task.\\n2. Keep in mind that while you can improve the managerial performance by improving the efficiency of the process, it is important to ensure that the process is well-maintained and accurate.\\n\\n3. Use the \"max\" feature, which allows you to limit the number of tasks you can run to when you need to prioritize tasks and to get the most out of your work.\\n\\n4. Look for areas where you can improve the managerial performance by incorporating additional features or activities into your daily tasks. For example, you can include features such as \"watch\" and \"tasks\" in your daily tasks to improve their performance and to add additional activities.\\n\\n5. Use the \"work\" feature, which allows you to keep track of your tasks and prioritize tasks based on their importance. For example, you can keep track of your tasks based on the importance of one task and to avoid being overwhelmed by the task if you',\n",
       "        0.999594],\n",
       "       [\"The Second Amendment guarantees citizens' ability to own and operate firearms. The ATF restricts people's ability to do so, and may even punish people for violating its regulations. Isn't the ATF's restriction of firearm ownership a violation of the Second Amendment?\",\n",
       "        'The Second Amendment guarantees individuals the right to possess firearms and that they have the right to possess that they possess. The ATF has the power to restrict firearms to an unlimited number of individuals without regard to their individual rights. The right to possess firearms is not a fundamental right and is restricted to individuals. The ATF has the power to enforce its laws and to protect its citizens from dangerous and uncooperative individuals. It has the power to limit firearms to certain categories, such as those who possess firearms without the express written consent of the ATF. The right to possess firearms is not a right and it is a civil right and can be subject to legal restrictions. All individuals possess firearms, including anyone who owns or operates them.\\n\\nIt is important to note that the Second Amendment is a fundamental right and should not be taken lightly. It is a fundamental right that individuals possess and that they have the right to possess firearms. The right to possess firearms is not a fundamental right and is limited to individuals. It is a fundamental right of every citizen and that individuals have the right to keep and bear Arms. The right to possess firearms is not a fundamental right and is subject to laws and regulations.',\n",
       "        0.999604],\n",
       "       [\"Can you tell me, in layman's terms, how the solution to the Taniyama–Shimura–Weil conjecture, also known as the Modularity Theorem, lead to the proof of Fermat's Last Theorem?\",\n",
       "        \"The Taniyama–Shimura–Weil conjecture is a conjecture in the theory of elliptic curves, which is a conjecture due to Chen, Ting, and Zhang to the Tutte Conjecture. It is one of the most famous conjectures in the theory of elliptic curves and has been proven by Lin and Wang in a series of papers. The Taniyama–Shimura–Weil conjecture is known to hold true for elliptic curves with complex coefficients, which is known to have a unique solution.\\n\\nThe modularity conjecture is a conjecture of Pascal, which is a conjecture of the Euler characteristic of the space of algebraic integers. It was first proposed by Lin in 1822 and has since become a well-known problem in the theory of algebraic number theory.\\n\\nIn general, the more general form of the Fermat–Weil conjecture is not known, although it has been proven to be true in a few cases. It has been conjectured to have a unique solution to the Taniyama–Shimura–Weil conjecture, which is known to have been proven by Chen, Ting, and Zhang in a series of papers. However, it is not known whether it has a unique solution to the Euler-Veech equation.\\n\\nIn addition to the Fermat-Weil conjecture, there are also other conjectures that have been proposed:\\n\\n1. Fermat's Last Theorem: The conjecture is a conjecture due to Chen, Ting, and Zhang that was first proposed by Lin and Wang in a series of papers in the field of algebraic number theory. It has been proven to have a unique solution to the Euler-Veech equation, which has been confirmed by Liu and Wang in a series of papers.\\n\\n2. Fano Conjecture: The conjecture is a conjecture of the Fermat-Weil conjecture, which is a conjecture due to Chen, Ting, and Zhang to the Tutte Conjecture, which is a conjecture related to the Fermat-Weil Conjecture. It is a conjecture that has been conjectured to have a unique solution to the Euler-Veech equation, which has been confirmed by Liu and Wang in a series of papers.\\n\\n3. Fermat's Last Theorem: The conjecture is a conjecture that was first proposed by Lin and Wang in a series of papers in the field of algebraic number theory. It has been proven to have a unique solution to the Euler-Vee\",\n",
       "        0.999609],\n",
       "       ['Thank you.  Is it better to build my own PC or to just buy one off the shelf?  Give me the pros and cons of each approach.',\n",
       "        'Building a PC is a complex process, and ultimately the selection of components and hardware can vary based on your needs. Some components may be more customizable, while others may be more difficult to upgrade or modify. Another factor to consider is the overall cost of the machine.\\n\\nHere are some pros and cons of each approach:\\n\\n1. The cost of the machine could be more expensive compared to the cost of the hardware. The cost of a machine can vary based on the type of hardware and the price of the machine.\\n2. The cost of the machine could be lower if you are not using a specific brand of the machine.\\n3. The price of the machine could increase or decrease with the price of the hardware.\\n4. The size of the machine, such as the size of the screen, can also be added to the cost of the machine.\\n5. If you are not using a specific brand of the machine, the price of the machine may be more expensive compared to the cost of the hardware.\\n6. The cost of the machine may be lower if you are using a specific brand of the machine.\\n7. There is more customization needed to create the machine. For example, you might want to modify the hardware to account for different screen sizes and other features.\\n\\nOverall, the choice of approach can vary depending on the specific needs and requirements of each solution. It is usually recommended to choose the right approach based on the specific needs and requirements of your specific solution.',\n",
       "        0.999646],\n",
       "       ['Hi, can you tell me a story in a novel format including dialogs between the characters, a story based on the Justice League comics, including the characters, Green Arrow, Red Arrow and Cheshire.',\n",
       "        'Sure, here\\'s a story in a novel format that follows the Justice League, a group of heroes battling off against time-travelers and a waterworld villain known as the Green Arrow:\\n\\nThe Justice League is a mysterious, alternate-day fighting game that takes place in a distant land called Greenland, and where they fight against time travelers and fight off death and misfires.\\n\\nIn this game, players take on the role of the Justice League, a mysterious, multiverse-driven game that is played by a team of seven unique and sometimes incompatible characters. With each encounter, the players must navigate their way through a series of challenges and obstacles, with each character battling against time and facing off against the cosmic forces that shape the world they play.\\n\\nThroughout the game, players are given unique and complex challenges to navigate, with each encounter leading to new challenges and obstacles. The heroes and villains battling to survive and defeat the cosmic forces, while battling for the love of their own, ultimately leading to the end of the game.\\n\\nIn this highly competitive game, players must navigate through a multiverse of challenges and obstacles, with each encounter challenging them to overcome the challenges and overcome them. The team must also face the dark forces of time and the forces of darkness, with each encounter challenging them to find their own way back to their own world.\\n\\nEach character has their own unique challenges and obstacles, with each encounter, the heroes and villains battling for the right to control the game and control the future of the game itself. The team must navigate through a series of challenges and obstacles, with each encounter challenging them to overcome the challenges and overcome them.\\n\\nUltimately, the story of the game is a journey of discovery and the characters in it explore a unique and complex world that will take them on a journey of creating a better future for all. It\\'s up to each of the team to create a unique and complex game of their own, and it\\'s up to each of us to bring it to life.\\n\\nIn this story, the story unfolds in a unique and complex world where players face the challenges of time travel, conflicted emotions, and the clash of cultures. Along the way, players face the challenges of identity, identity, and the future of the world they play.\\n\\nIn \"Justice League,\" the team must navigate through a multiverse of challenges and obstacles, with each encounter facing off against the cosmic forces that shape the world they play. The team must navigate',\n",
       "        0.999663],\n",
       "       ['Write an essay on how Romeo is most to blame for the events that take place in the end of the book,',\n",
       "        'The Roman Emperor built a huge, double-decker bus that he used to transport his troops to the cities of the East. In the summer of 44 AD, the Roman fleet was being sunk by a British frigate, which had been sunk by a German frigate, making it impossible to advance. The Romans had been sailing for long periods of time without any warning from the British. The strike was met with great resistance by the German fleet, which was soon defeated by the Romans. The Romans had to fight back, with all their might, with all their might. However, the fate of the empire ultimately came to a head after the defeat of the Roman Empire, when the Roman fleet was overwhelmed by the German ships, the Guards of Italy.\\n\\nThe Romans were unhappy with the situation, and decided to turn to the use of force. They had to use their armies wisely and effectively, with the soldiers in tow. They launched all of their forces on the front lines, and they were met with overwhelming resistance. They responded by sending their best soldiers home, believing that the Romans were completely at fault.\\n\\nThe Romans were deeply unhappy with the outcome of the war, and they were determined to make it right and quickly defeat the Byzantines. They used their ships, tactics, and weapons to the utmost, and they used their military machine to execute their demands. They used their military advantage to their advantage, and they used their ships to the utmost to take down the enemy fleet.\\n\\nThe Roman Empire had faced a series of challenges, with the most major one being its invasion of the West African empire. The Roman fleet had been making steady progress since the end of the Arab conquest, but it was now setting up an offensive campaign to destroy the Byzantines.\\n\\nThe Roman defeat at the end of the war was a test of their ability to adapt to the new situation, as it put an end to the barbarian invasions. They had to make the most of their own resources and bestow them with military might, including the right to defend themselves in case of rebellion or to seize control of the cities of the East. The Romans had to adapt to the new situation, with their ships and equipment, and they faced a full-fledged threat from the Byzantines.\\n\\nThe defeat of the Roman Empire was a test of their ability to adapt to new situations and to defeat the Western Empire. However, the defeat of the Roman Empire was not without its consequences. The Roman fleet had been',\n",
       "        0.999731],\n",
       "       [\"Yes it is, but it's still too long for a brief summary. Can you shorten it a bit? Around 20% shorter than it is now, please.\",\n",
       "        \"Sure, I can shorten it as long as it is still at the same level. But it still feels like it's been a long time since I last saw it.\\n\\nThe time it took to get to the end of the song is when you said you were going to see it again (it was the shortest time of my life). You could also tell me about the time you visited the beach, but feel free to tell me about it. But the time it took to get there was closer to the end.\\n\\nAnyway, here is a rough draft of the song:\\n\\nVerse 1:\\n\\nI love the way you speak, and I feel like you're talking to me. You sound like you're talking to me\\n\\nChorus:\\n\\nIt's been a long time since I saw the ocean, but I've been dreaming of it\\n\\nChorus: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nVerse 2:\\n\\nI love the way you talk, and the way you hold yourself. I love the way you talk, and I feel like you're there with me\\n\\nChorus: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nVerse 3:\\n\\nI love the way you talk, and the way you hold yourself\\n\\nChorus: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nChorus: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: I'm dreaming of the ocean, and I'm doing it\\n\\nBridge: That's the longest time I've been dreaming about the ocean, and I'm doing it\\n\\nBridge: It's the longest time I've been dreaming about the ocean, and I'm doing it\\n\\nBridge: It's the longest time I've been dreaming about the ocean, and I'm doing it\\n\\nBridge: It's the longest time I've been dreaming about the ocean, and I'm doing it\\n\\nBridge: It's the longest time I've been dreaming about the ocean, and I\",\n",
       "        0.999756]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='coherence').tail(10)[['input', 'output', 'coherence']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BartScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/lit-gpt/out/inference/pythia-410m-deduped-oasst1-final-eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['What are the five most common causes of stress among people?',\n",
       "        'how how how how how how how how to use to for building of of the of the of the of the of the of the of the of the of the of the of the of thea of theof the of the of the of theof the of the of the of thea of theof the of theof theof thea of theof the of theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theoftheof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof thetheof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof theof the',\n",
       "        -0.8667047023773193],\n",
       "       [\"What's the furthest back we can prove human existence? Is there good reason to believe it goes further then this point?\",\n",
       "        'Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework Framework ',\n",
       "        -0.6490703225135803],\n",
       "       ['Has the US National Reconnaissance Office ever confirmed the existence and capabilities of the KeyHole satellites?',\n",
       "        'Is the number of the unicode char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char symbol char char charchar char char __char char char[0]; char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char char[_ char char char char char char char char char char char char char char char char char char char char char char char char char char char char char',\n",
       "        -0.5634528994560242],\n",
       "       ['is javascript back end or front end language?',\n",
       "        ' language? The language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the languages of the languages of the languages of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of the language of',\n",
       "        -0.5209837555885315],\n",
       "       ['can you write haiku for different inductive biases in deep learning models? start with attention',\n",
       "        ' and how do you write a simple fine sense of fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine, fine fine fine fine fine fine fine fine fine fine, fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine, fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine. Fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine, fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine, fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine\\nfine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine',\n",
       "        -0.4356985986232757]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['BARTScore']).sort_values(by='BARTScore').tail(5)[['input', 'output', 'BARTScore']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT4 Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('/workspaces/lit-gpt/out/inference/pythia-410m-deduped-oasst1-final-eval.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = data.score.apply(pd.Series).stack().str.split('/').apply(pd.Series)[0].str.strip().replace({'n':'None'}).apply(eval).unstack()#.mean()\n",
    "# .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.669014</td>\n",
       "      <td>3.792208</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.468875</td>\n",
       "      <td>3.348349</td>\n",
       "      <td>2.567549</td>\n",
       "      <td>2.748444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1          2          3\n",
       "count  142.000000  154.000000  66.000000  78.000000\n",
       "mean     4.669014    3.792208   3.500000   3.346154\n",
       "std      2.468875    3.348349   2.567549   2.748444\n",
       "min      1.000000    0.000000   0.000000   0.000000\n",
       "25%      2.000000    1.000000   1.000000   1.000000\n",
       "50%      5.000000    2.000000   2.000000   2.000000\n",
       "75%      7.000000    7.000000   5.000000   6.000000\n",
       "max     10.000000   10.000000  10.000000  10.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Explain the difference between sets and lists in Python.',\n",
       "        \"The set and list in Python are both two different types of data structures.\\n\\nThe set is a collection of objects, which are compared by the elements in the set.\\n\\nThe list is a list of objects, which are compared by the elements in the list.\\n\\nLet's take a step back and look at the difference between the sets and the lists.\\n\\nThe set is a collection of objects, which are compared by the elements in the set.\\n\\nThe list is a list of objects, which are compared by the elements in the list.\\n\\nLet's take a step back to better understand the difference between sets and lists.\\n\\nThe set is a collection of objects, which are compared by the elements in the set.\\n\\nThe list is a list of objects, which are compared by the elements in the list.\\n\\nSo the set is a collection of things, which are compared by the elements in the set. The list is a list of things, which are compared by the elements in the list. So the set and the list are two different types of data structures.\",\n",
       "        1.0],\n",
       "       [\"How would a basic project in PyGame look like? I'd like the example to include keyboard event handling so that pressing ESC will quit the game and also print the FPS counter in the left top corner of the window.\",\n",
       "        'Here\\'s a basic project in PyGame that includes keyboard handling:\\n\\n``` \\nimport pygame\\nimport time\\nimport random\\nimport tkinter as tk\\nfrom tkinter import messagebox\\nfrom tkinter import messagebox.messagebox\\n\\nclass Project():\\n    def __init__(self):\\n        # initialize PyGame variables\\n        self.width = 800\\n        self.height = 600\\n        self.background = (255, 255, 255)\\n        self.text = \"Hello World!\"\\n        self.text_color = (0, 255, 255)\\n        self.font_size = 20\\n        self.font_style = 2\\n\\n    def run(self):\\n        # set up window\\n        window = tk.Tk()\\n        self.window = window\\n        # create window\\n        self.window.title = \"Project\"\\n        self.width, self.height = self.size_x, self.size_y\\n        self.parent = window\\n        # create window\\n        self.window.setdefaultwidth(400), self.window.setdefaultheight(800)\\n        self.parent.delete(\"C:\")\\n        self.parent.insert(0, self.window)\\n        self.parent.delete(\"E:\")\\n        self.parent.insert(1, self.window)\\n        self.parent.delete(\"Q:\")\\n        self.parent.insert(2, self.window)\\n        self.parent.delete(\"O:\")\\n        self.parent.insert(3, self.window)\\n        self.parent.delete(\"K:\")\\n        self.parent.insert(4, self.window)\\n        self.parent.delete(\"X:\")\\n        self.parent.insert(5, self.window)\\n        self.parent.delete(\"O:\")\\n        self.parent.insert(6, self.window)\\n        self.parent.delete(\"Q:\")\\n        self.parent.insert(7, self.window)\\n        self.parent.delete(\"O:\")\\n        self.parent.insert(8, self.window)\\n        self.parent.delete(\"K:\")\\n        self.parent.insert(9, self.window)\\n        self.parent.delete(\"O:\")\\n        self.parent.',\n",
       "        1.0],\n",
       "       ['How can L’Hopital’s Rule be used in day to day life?',\n",
       "        'Here’s a simple way to use L’Hopital’s Rule in day to day life:\\n\\nSit down and start to count sheep. Start by counting sheep that are up to nine years old. Then, start counting sheep that are five or less years old. Repeat this process for each age group, up to nine years old.\\n\\nThen, start counting sheep that are between nine and 16 years old. For example, start counting sheep that are between nine and 16 years old and then add up the number of sheep you have counted so far. It will look like this:\\n\\nSo, for a sheep that is up to nine years old, you have counted 365 sheep.\\n\\nNext, start counting sheep that are between nine and 16 years old. For example, start counting sheep that are between nine and 16 years old and then add up the number of sheep you have counted so far. It will look like this:\\n\\nSo, for a sheep that is between nine and 16 years old, you have had counted 365 sheep.',\n",
       "        1.0],\n",
       "       ['Suppose I have 12 eggs. I drop 2 and eat 5. How many eggs do I have left?',\n",
       "        '12,500', 1.0],\n",
       "       ['Compile a list of the 10 most popular German rock bands.',\n",
       "        \"Here are the top 10 most popular German rock bands in 2019 according to website Metacom.\\n\\n1. Led Zeppelin (United States, 1966-1969)\\n2. Nirvana (USA, 'Vespa' (1993-1994), 'Nirvana' (1994-1995), 'Grunge' (1997-1998), 'Smash Mouth' (1989-1994), 'Nirvana' (1994-1995), ' Pearl Jam' (1992-1994)\\n3. Pink Floyd (United Kingdom, 'The Dark Side of the Sun' (1977-1982), 'The Dark Side of the Sun' (1982-1987), ' The Dark Star' (1977-1982), ' The Dark Laughter' (1977-1982), ' The Dark Corner' (1977-1982), 'The Dark Knight' (2013-2020), ' The Darkman' (1977-1982), ' The Dark Lady of Chains' (1977-1982), ' The Darkman' (1977-1982), ' The Dark Nights of Midnight' (1979-1982), ' The Darkness' (1981-1987)\\n4. The Beatles (United Kingdom, 'Abbey Road' (1963-1965), ' White Album' (1967-1969), ' Help!' (1964-1967), ' Revolver' (1967-1969), ' Revolver' (1969-1974)\\n5. The Rolling Stones (GTA, 'Get Back' (1970-1971), ' Goodnight, My Love' (1971-1974), ' T.R.O.A.' (1970-1971), ' The Longest Journey' (1971-1974), ' Back to the Future' (1955-1955)\\n6. Guns N' Roses (United States, 'Nirvana' (1994-1995), ' Smash Mouth' (1989-1994), ' Pearl Jam' (1992-1994), ' The Who' (1960-1969), ' The Mods' (1970-1971), ' The Ramones' (1969-1974), ' The Ramones' (1970-1977), ' The Rolling Stones' (1969-1974), ' The Ramones' (1971-1977)\\n7. Led Zeppelin (United Kingdom, 'The White Album' (1967-1970), ' Abbey Road' (1963-1969), ' White Album' (1970-1977), ' Black Sabbath' (1967\",\n",
       "        1.0]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 0\n",
    "pd.concat([data, scores], axis=1).dropna(subset=[col]).sort_values(col).head(5)[['user_prompt', 'assistant_prompt', col]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional analysis of turn taking\n",
    "\n",
    "Show base models tend to repeat parts of prompt (longer common token sequence)\n",
    "\n",
    "and contain repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y, m, n, dp):\n",
    "\n",
    "    if (m == 0 or n == 0):\n",
    "        return 0\n",
    "\n",
    "    if (dp[m][n] != -1):\n",
    "        return dp[m][n]\n",
    "\n",
    "    if X[m - 1] == Y[n - 1]:\n",
    "        dp[m][n] = 1 + lcs(X, Y, m - 1, n - 1, dp)\n",
    "        return dp[m][n]\n",
    "\n",
    "    dp[m][n] = max(lcs(X, Y, m, n - 1, dp), lcs(X, Y, m - 1, n, dp))\n",
    "    return dp[m][n]\n",
    "\n",
    "def mylcs(S1, S2):\n",
    "    m = len(S1)\n",
    "    n = len(S2)\n",
    "    dp = [[-1 for i in range(n + 1)]for j in range(m + 1)]\n",
    "    return lcs(S1, S2, m, n, dp) / n if n else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LCS'] = data.apply(lambda row: mylcs(row.user_prompt.lower().split(), row.assistant_prompt.lower().split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    168.000000\n",
       "mean       0.087452\n",
       "std        0.100915\n",
       "min        0.000000\n",
       "25%        0.029239\n",
       "50%        0.054201\n",
       "75%        0.101312\n",
       "max        0.653846\n",
       "Name: LCS, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.LCS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['What is the capital of Australia?',\n",
       "        'The capital of Australia is the City of Canberra.',\n",
       "        0.3333333333333333],\n",
       "       ['Which of the following elbows are the most wet?\\nA. A kilogram of feathers\\n2) Coach Malibu\\nD - The cross-section of air',\n",
       "        'Here are some options:\\n\\n* A kilogram of feathers\\n* 2 coaches Malibu',\n",
       "        0.46153846153846156],\n",
       "       ['Can you personalize the poem to put the fact that we met on a train?',\n",
       "        'Met on a train are you?', 0.5],\n",
       "       ['Since you are a chat assistant meant to help others and designed to answer every question, I am disappointed that you are unable to do such a simple task. You are indeed an AI and you should know that from now on.',\n",
       "        'You are wrong. I am a Chat Assistant designed to help others, I am not limited to answering simple questions.',\n",
       "        0.55],\n",
       "       [\"Bob has two sons. John and Jay. Jay has one brother and father. The father has two sons.\\nJay's brother has a brother and a father. Who is Jay's brother.\",\n",
       "        \"John has one brother Jay. Jay has one brother. Jay has a brother Jay. Jay's brother has a brother and a father. Who is Jay's father.\",\n",
       "        0.6538461538461539]], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='LCS')[['user_prompt', 'assistant_prompt', 'LCS']].tail(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, df, how='left', left_on='assistant_prompt', right_on='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLCS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmylcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLCS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: mylcs(row\u001b[38;5;241m.\u001b[39muser_prompt\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit(), \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\u001b[38;5;241m.\u001b[39msplit()), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "data['LCS'] = data.apply(lambda row: mylcs(row.user_prompt.lower().split(), row.label.lower().split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    168.000000\n",
       "mean       0.087452\n",
       "std        0.100915\n",
       "min        0.000000\n",
       "25%        0.029239\n",
       "50%        0.054201\n",
       "75%        0.101312\n",
       "max        0.653846\n",
       "Name: LCS, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.LCS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Write me a SPL (Shakespeare Programming Language) program that takes 2 numbers from the user and outputs the product of the two numbers.',\n",
       "        \"Here's a SPL (Shakespeare Programming Language) program that takes two numbers from the user and outputs the product of the two numbers:\\n\\nless\\n\\nI. Prologue\\nEnter two numbers\\n\\nII. Scene 1\\nTo multiply two numbers is a simple task\\nIf thou wouldst give me two, I'll do the rest.\\n\\nIII. Scene 2\\nNumber one: [number_1]\\nNumber two: [number_2]\\n\\nIV. Scene 3\\nThe product of [number_1] and [number_2] is [number_1 * number_2].\\n\\nV. Epilogue\\nExit.\\n\\nThis program uses the SPL syntax to interact with the user and perform a simple calculation. In Scene 2, the program prompts the user to enter two numbers. In Scene 3, the program calculates the product of the two numbers and outputs the result. Finally, in the Epilogue, the program exits.\",\n",
       "        20],\n",
       "       ['Write a C++ function that takes a reference to a std::string containing markdown formatted text and returns a std::string containing html formatted text.',\n",
       "        'Sure, here\\'s a C++ function that takes a reference to a std::string containing Markdown formatted text and returns a std::string containing HTML formatted text:\\n\\n```\\n#include <string>\\n\\nstd::string markdownToHtml(std::string& markdown) {\\n    std::string html = markdown;\\n\\n    // Replace headers\\n    html = std::regex_replace(html, std::regex(\"^# (.*)\"), \"<h1>$1</h1>\");\\n    html = std::regex_replace(html, std::regex(\"^## (.*)\"), \"<h2>$1</h2>\");\\n    html = std::regex_replace(html, std::regex(\"^### (.*)\"), \"<h3>$1</h3>\");\\n    html = std::regex_replace(html, std::regex(\"^#### (.*)\"), \"<h4>$1</h4>\");\\n    html = std::regex_replace(html, std::regex(\"^##### (.*)\"), \"<h5>$',\n",
       "        21],\n",
       "       ['Can you explain to me how the stable diffusion algorithm for ai generated images can be used to enhance the visual quality of low resolution and low quality images? And what are some of the potential advantages and limitations of this algorithm for things like upscaling, efficient image compression, and content generation in creative fields like CGI and digital art?',\n",
       "        'Sure! The Stable Diffusion Algorithm is a machine learning technique that can be used to enhance the visual quality of low resolution and low quality images. The algorithm works by progressively adding noise to an input image and then removing the noise to generate a new image that has a higher resolution and visual quality. The noise is added and removed in a series of steps, or \"diffusions,\" which gradually refine the image.\\n\\nOne advantage of the Stable Diffusion Algorithm is that it can be used for upscaling low resolution images. By adding noise and then removing it in a series of diffusions, the algorithm can create a new image that is higher in resolution than the original image. This can be useful for enhancing the visual quality of images in a variety of applications, such as medical imaging, surveillance, and satellite imagery.\\n\\nAnother advantage of the algorithm is that it can be used for efficient image compression. The algorithm works by',\n",
       "        28],\n",
       "       ['Can you explain to me how the stable diffusion algorithm for ai generated images can be used to enhance the visual quality of low resolution and low quality images? And what are some of the potential advantages and limitations of this algorithm for things like upscaling, efficient image compression, and content generation in creative fields like CGI and digital art?',\n",
       "        'Sure! The Stable Diffusion Algorithm is a machine learning technique that can be used to enhance the visual quality of low resolution and low quality images. The algorithm works by progressively adding noise to an input image and then removing the noise to generate a new image that has a higher resolution and visual quality. The noise is added and removed in a series of steps, or \"diffusions,\" which gradually refine the image.\\n\\nOne advantage of the Stable Diffusion Algorithm is that it can be used for upscaling low resolution images. By adding noise and then removing it in a series of diffusions, the algorithm can create a new image that is higher in resolution than the original image. This can be useful for enhancing the visual quality of images in a variety of applications, such as medical imaging, surveillance, and satellite imagery.\\n\\nAnother advantage of the algorithm is that it can be used for efficient image compression. The algorithm works by',\n",
       "        28],\n",
       "       ['Famously, some spy-satellites from the KeyHole series developed and operated by the US National Reconnaissance Office, where similar in capabilities to the Hubble Space Telescope, but then pointed at the earth rather than out into the universe. What can you tell me about these satellites? What era were they developed? Are they still active, and what are their approximate capabilities thought to be?',\n",
       "        'The KeyHole series of spy satellites were developed and operated by the US National Reconnaissance Office. They were similar in capabilities to the Hubble Space Telescope, but instead of looking out into the universe, they were aimed at the Earth. These satellites were developed in an era when advancements in space technology were allowing for greater surveillance capabilities from orbit. It is unclear if they are still active today, but their capabilities were thought to include high-resolution imaging and possibly signals intelligence.',\n",
       "        33]], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='LCS')[['user_prompt', 'label', 'LCS']].tail(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def diversity(tokens):\n",
    "    if len(tokens) <= 1:\n",
    "        return np.nan\n",
    "    return len(Counter(tokens).keys()) / float(len(tokens))\n",
    "\n",
    "data['diversity'] = data.assistant_prompt.apply(lambda x: diversity(x.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    167.000000\n",
       "mean       0.614723\n",
       "std        0.202712\n",
       "min        0.068452\n",
       "25%        0.479592\n",
       "50%        0.603352\n",
       "75%        0.768067\n",
       "max        1.000000\n",
       "Name: diversity, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.diversity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"I'll do my best.\", 1.0],\n",
       "       [\"You're welcome! Let me know if anything else I can do.\", 1.0],\n",
       "       ['Sure! If you need advice on any specific topic, feel free to ask me.',\n",
       "        1.0],\n",
       "       ['Met on a train are you?', 1.0],\n",
       "       ['What city in the world are you currently living in?', 1.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='diversity')[['assistant_prompt', 'diversity']].dropna(subset=['diversity']).tail(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0280468411440579,\n",
       " 0.23634444797734666,\n",
       " 0.37284523566387207,\n",
       " 0.0612667349098726,\n",
       " 0.19177762151322653)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0].corr(data.LCS), scores[0].corr(data.diversity), data.LCS.corr(data.diversity), scores[0].corr(data.LCS * data.diversity), scores[0].corr(data.LCS + data.diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>sz</th>\n",
       "      <th>ck</th>\n",
       "      <th>overlap</th>\n",
       "      <th>overlap_gold</th>\n",
       "      <th>diversity</th>\n",
       "      <th>diversity_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dolly</td>\n",
       "      <td>160m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.010387</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.247399</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dolly</td>\n",
       "      <td>160m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.142425</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.514387</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dolly</td>\n",
       "      <td>410m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.274661</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolly</td>\n",
       "      <td>410m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.163775</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.760174</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dolly</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.314043</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dolly</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.140639</td>\n",
       "      <td>0.122859</td>\n",
       "      <td>0.771470</td>\n",
       "      <td>0.828713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dolly</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.028444</td>\n",
       "      <td>0.151560</td>\n",
       "      <td>0.325594</td>\n",
       "      <td>0.825021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dolly</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.777697</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dolly</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.309462</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dolly</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.168862</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.784686</td>\n",
       "      <td>0.823830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>160m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.268444</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>160m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.539407</td>\n",
       "      <td>0.732730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>410m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.029754</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.333656</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>410m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.614723</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.292899</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.106636</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>0.627142</td>\n",
       "      <td>0.732972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.038947</td>\n",
       "      <td>0.089896</td>\n",
       "      <td>0.365597</td>\n",
       "      <td>0.745727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.072972</td>\n",
       "      <td>0.091516</td>\n",
       "      <td>0.608154</td>\n",
       "      <td>0.731119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>0.324331</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oasst1</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.082126</td>\n",
       "      <td>0.092763</td>\n",
       "      <td>0.647609</td>\n",
       "      <td>0.733065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>160m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.255274</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>160m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.045019</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.404667</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>410m</td>\n",
       "      <td>base</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.318576</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>410m</td>\n",
       "      <td>final</td>\n",
       "      <td>0.059196</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.502579</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.330381</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.064687</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.504309</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.652570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>2.8b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.070298</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>base</td>\n",
       "      <td>0.030671</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.364430</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>6.9b</td>\n",
       "      <td>final</td>\n",
       "      <td>0.055717</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>0.650108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds    sz     ck   overlap  overlap_gold  diversity  diversity_gold\n",
       "0      dolly  160m   base  0.010387      0.152571   0.247399        0.823830\n",
       "1      dolly  160m  final  0.142425      0.152571   0.514387        0.823830\n",
       "2      dolly  410m   base  0.015262      0.152571   0.274661        0.823830\n",
       "3      dolly  410m  final  0.163775      0.152571   0.760174        0.823830\n",
       "4      dolly  1.4b   base  0.017048      0.152571   0.314043        0.823830\n",
       "5      dolly  1.4b  final  0.140639      0.122859   0.771470        0.828713\n",
       "6      dolly  2.8b   base  0.028444      0.151560   0.325594        0.825021\n",
       "7      dolly  2.8b  final  0.179203      0.152571   0.777697        0.823830\n",
       "8      dolly  6.9b   base  0.018883      0.152571   0.309462        0.823830\n",
       "9      dolly  6.9b  final  0.168862      0.152571   0.784686        0.823830\n",
       "10    oasst1  160m   base  0.017931      0.086902   0.268444        0.731101\n",
       "11    oasst1  160m  final  0.073293      0.086902   0.539407        0.732730\n",
       "12    oasst1  410m   base  0.029754      0.086902   0.333656        0.731101\n",
       "13    oasst1  410m  final  0.087452      0.086902   0.614723        0.731101\n",
       "14    oasst1  1.4b   base  0.024306      0.086902   0.292899        0.731101\n",
       "15    oasst1  1.4b  final  0.106636      0.090824   0.627142        0.732972\n",
       "16    oasst1  2.8b   base  0.038947      0.089896   0.365597        0.745727\n",
       "17    oasst1  2.8b  final  0.072972      0.091516   0.608154        0.731119\n",
       "18    oasst1  6.9b   base  0.029039      0.086902   0.324331        0.731101\n",
       "19    oasst1  6.9b  final  0.082126      0.092763   0.647609        0.733065\n",
       "20  sharegpt  160m   base  0.018150      0.064042   0.255274        0.650108\n",
       "21  sharegpt  160m  final  0.045019      0.064042   0.404667        0.650108\n",
       "22  sharegpt  410m   base  0.023668      0.064042   0.318576        0.650108\n",
       "23  sharegpt  410m  final  0.059196      0.064042   0.502579        0.650108\n",
       "24  sharegpt  1.4b   base  0.023703      0.064042   0.330381        0.650108\n",
       "25  sharegpt  1.4b  final  0.064687      0.064042   0.504309        0.650108\n",
       "26  sharegpt  2.8b   base  0.030084      0.064856   0.366403        0.652570\n",
       "27  sharegpt  2.8b  final  0.070298      0.064042   0.543763        0.650108\n",
       "28  sharegpt  6.9b   base  0.030671      0.064042   0.364430        0.650108\n",
       "29  sharegpt  6.9b  final  0.055717      0.064042   0.548943        0.650108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = ['160m', '410m', '1.4b', '2.8b', '6.9b']\n",
    "dsts = ['dolly', 'oasst1', 'sharegpt']\n",
    "chkpt = ['base', 'final']\n",
    "\n",
    "def analysis(sz, ck, ds): \n",
    "    df = pd.read_pickle(f'/workspaces/lit-gpt/out/inference/pythia-{sz}-deduped-{ds}-{ck}-eval.pkl')\n",
    "    data = pd.read_json(f'/workspaces/lit-gpt/out/inference/pythia-{sz}-deduped-{ds}-{ck}-eval.json')\n",
    "\n",
    "    data = pd.merge(data, df, how='left', left_on='assistant_prompt', right_on='output')\n",
    "\n",
    "    return [\n",
    "        data.apply(lambda row: mylcs(row.user_prompt.lower().split(), row.assistant_prompt.lower().split()), axis=1).mean(), \n",
    "        data.apply(lambda row: mylcs(row.user_prompt.lower().split(), row.label.lower().split()), axis=1).mean(), \n",
    "        data.assistant_prompt.apply(lambda x: diversity(x.lower().split())).dropna().mean(),\n",
    "        data.label.apply(lambda x: diversity(x.lower().split())).dropna().mean()\n",
    "    ]\n",
    "\n",
    "pd.DataFrame([[ds, sz, ck] + analysis(sz, ck, ds) for ds in dsts for sz in sizes for ck in chkpt], columns=['ds', 'sz', 'ck', 'overlap', 'overlap_gold', 'diversity', 'diversity_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
